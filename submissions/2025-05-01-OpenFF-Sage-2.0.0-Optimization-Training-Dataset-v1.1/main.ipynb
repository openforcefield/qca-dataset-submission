{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58a7c165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import datetime\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import periodictable\n",
    "\n",
    "from qcportal.external import scaffold\n",
    "from qcportal import PortalClient\n",
    "from qcportal.optimization import OptimizationDatasetEntry\n",
    "from qcportal.torsiondrive import TorsiondriveDatasetEntry\n",
    "DatasetEntry = {\"optimization\": OptimizationDatasetEntry, \"torsiondrive\": TorsiondriveDatasetEntry}\n",
    "\n",
    "ADDRESS = \"https://api.qcarchive.molssi.org:443/\"\n",
    "client = PortalClient(ADDRESS, cache_dir=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865126a7",
   "metadata": {},
   "source": [
    "# Get Records and Molecular Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d506e035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting record ids\n"
     ]
    }
   ],
   "source": [
    "# _________ Pull Record IDs of Relevant Datasets ____________\n",
    "print(\"Getting record ids\")\n",
    "\n",
    "file = requests.get(\n",
    "    \"https://raw.githubusercontent.com/openforcefield/openff-sage/37a36e7eeaf6cdca795847089a288bdff168c08a/data-set-curation/quantum-chemical/data-sets/1-2-0-opt-set-v3.json\"\n",
    ")\n",
    "data = json.loads(file.content)\n",
    "provenance = data[\"provenance\"]\n",
    "# list with: {type, record_id, cmiles, inchi_key}\n",
    "entry_dicts = data[\"entries\"][ADDRESS]\n",
    "dataset_type = entry_dicts[0][\"type\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33a76ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting records\n"
     ]
    }
   ],
   "source": [
    "# _________ Get Records ____________\n",
    "print(\"Getting records\")\n",
    "records = client.get_records([int(x[\"record_id\"]) for x in entry_dicts], missing_ok=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e2fbdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmiles_by_record_id = {\n",
    "    int(x[\"record_id\"]): {\"cmiles\": x[\"cmiles\"], \"mol\": None} \n",
    "    for x in entry_dicts\n",
    "}\n",
    "for record in records:\n",
    "    cmiles_by_record_id[record.id][\"mol\"] = record.initial_molecule\n",
    "    \n",
    "cmiles_count = defaultdict(Counter)\n",
    "molecules = []\n",
    "for recid, x in cmiles_by_record_id.items():\n",
    "    cmiles = x[\"cmiles\"]\n",
    "\n",
    "    if cmiles not in cmiles_count:\n",
    "        molecules.append(x[\"mol\"])\n",
    "    hash = x[\"mol\"].get_hash()\n",
    "    cmiles_count[cmiles][hash] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c32e1770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Molecular Statistics\n"
     ]
    }
   ],
   "source": [
    "# _________ Pull Statistics from Dataset ____________\n",
    "     \n",
    "print(\"Generating Molecular Statistics\")\n",
    "\n",
    "lx = len(cmiles_count)\n",
    "n_confs, n_heavy_atoms, masses, unique_charges = np.zeros(lx), [], np.zeros(lx), np.zeros(lx)\n",
    "elements = []\n",
    "for i, (cmiles, hashes) in enumerate(cmiles_count.items()):\n",
    "    n_confs[i] = len(hashes)\n",
    "    n_heavy_atoms.append(len([x for x in molecules[i].symbols if x != \"H\"]))\n",
    "    elements.extend(list(set([x for x in molecules[i].symbols])))\n",
    "    masses[i] = sum([getattr(periodictable, x).mass for x in molecules[i].symbols])\n",
    "    unique_charges[i] = molecules[i].molecular_charge\n",
    "    \n",
    "unique_charges = sorted(set(unique_charges))\n",
    "\n",
    "elements = sorted(list(set(elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf1a7e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Heavy Atom Counts\n",
      "  4: 2\n",
      "  5: 3\n",
      "  6: 4\n",
      "  7: 7\n",
      "  8: 20\n",
      "  9: 19\n",
      " 10: 46\n",
      " 11: 56\n",
      " 12: 81\n",
      " 13: 81\n",
      " 14: 94\n",
      " 15: 94\n",
      " 16: 59\n",
      " 17: 59\n",
      " 18: 47\n",
      " 19: 38\n",
      " 20: 36\n",
      " 21: 45\n",
      " 22: 30\n",
      " 23: 23\n",
      " 24: 21\n",
      " 25: 29\n",
      " 26: 6\n",
      " 27: 11\n",
      " 28: 16\n",
      " 29: 10\n",
      " 30: 8\n",
      " 31: 16\n",
      " 32: 16\n",
      " 33: 11\n",
      " 34: 11\n",
      " 35: 5\n",
      " 36: 15\n",
      " 37: 7\n",
      " 38: 8\n",
      " 39: 5\n",
      "* Number of unique molecules: 1039\n",
      "* Number of conformers: 3663\n",
      "* Number of conformers (min, mean, max): 1.00, 3.53, 10.00\n",
      "* Molecular weight (min, mean, max): 76.05, 261.37, 544.64\n",
      "* Charges: -2.0, -1.0, 0.0, 1.0\n"
     ]
    }
   ],
   "source": [
    "# _________ Write Output Part 1 (Run Before Approval) ____________\n",
    "\n",
    "print(\"\\n# Heavy Atom Counts\")\n",
    "counts1 = Counter(n_heavy_atoms)\n",
    "for n_heavy in sorted(counts1):\n",
    "    print(f\"{str(n_heavy):>3}: {counts1[n_heavy]}\")\n",
    "\n",
    "print(\"* Number of unique molecules: {}\".format(len(cmiles_count)))\n",
    "print(\"* Number of conformers:\", int(sum(n_confs)))\n",
    "print(\n",
    "    \"* Number of conformers (min, mean, max): {:.2f}, {:.2f}, {:.2f}\".format(\n",
    "        min(n_confs), np.mean(n_confs), max(n_confs)\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"* Molecular weight (min, mean, max): {:.2f}, {:.2f}, {:.2f}\".format(\n",
    "        min(masses), np.mean(masses), max(masses)\n",
    "    )\n",
    ")\n",
    "print(\"* Charges: {}\".format(\", \".join([str(x) for x in unique_charges])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1471650",
   "metadata": {},
   "source": [
    "# Make New Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529e82b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing new dataset\n"
     ]
    }
   ],
   "source": [
    "# _________ Initialize New Dataset ____________\n",
    "print(\"Initializing new dataset\")\n",
    "\n",
    "with open(\"ds_info.json\") as f:\n",
    "    dataset_information = json.load(f)\n",
    "\n",
    "#dataset = client.get_dataset(dataset_type, dataset_information[\"dataset_name\"])\n",
    "dataset = client.add_dataset(\n",
    "    dataset_type,\n",
    "    dataset_information[\"dataset_name\"],\n",
    "    tagline=dataset_information[\"dataset_tagline\"],\n",
    "    description=dataset_information[\"description\"],\n",
    "    provenance=provenance,\n",
    "    default_tag=\"openff\",\n",
    "    owner_user=\"openffbot\",\n",
    "    extras={\n",
    "        \"submitter\": dataset_information[\"metadata.submitter\"],\n",
    "        \"creation_data\": str(datetime.date.today()),\n",
    "        'collection_type': 'OptimizationDataset',\n",
    "        'long_description_url': dataset_information[\"metadata.long_description_url\"],\n",
    "        \"short description\": dataset_information[\"dataset_tagline\"],\n",
    "        \"dataset_name\": dataset_information[\"dataset_name\"],\n",
    "        \"elements\": provenance['applied-filters']['ElementFilter-3']['allowed_elements'],\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e29790c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting records\n",
      "Failed record 19095358, [{'record_id': 19095355, 'dataset_id': 270, 'dataset_type': 'optimization', 'dataset_name': 'OpenFF Gen 2 Opt Set 5 Bayer', 'entry_name': 'cc(=ccoc1cc(ccc1oc)[c@@h]2cc(=o)nc2)c-0', 'specification_name': 'default'}, {'record_id': 19095355, 'dataset_id': 427, 'dataset_type': 'optimization', 'dataset_name': 'OpenFF Sage 2.0.0 Optimization Training Dataset v1.1', 'entry_name': 'cc(=ccoc1cc(ccc1oc)[c@@h]2cc(=o)nc2)c-0', 'specification_name': 'default'}]\n",
      "Failed record 19095359, [{'record_id': 19095355, 'dataset_id': 270, 'dataset_type': 'optimization', 'dataset_name': 'OpenFF Gen 2 Opt Set 5 Bayer', 'entry_name': 'cc(=ccoc1cc(ccc1oc)[c@@h]2cc(=o)nc2)c-0', 'specification_name': 'default'}, {'record_id': 19095355, 'dataset_id': 427, 'dataset_type': 'optimization', 'dataset_name': 'OpenFF Sage 2.0.0 Optimization Training Dataset v1.1', 'entry_name': 'cc(=ccoc1cc(ccc1oc)[c@@h]2cc(=o)nc2)c-0', 'specification_name': 'default'}]\n",
      "Copying entries from ds-251 (1 of 6)\n",
      "Copying entries from ds-253 (2 of 6)\n",
      "Copying entries from ds-68 (3 of 6)\n",
      "Copying entries from ds-254 (4 of 6)\n",
      "Copying entries from ds-270 (5 of 6)\n",
      "Copying entries from ds-69 (6 of 6)\n"
     ]
    }
   ],
   "source": [
    "# Get ds associated with specifications\n",
    "# _________ Get Records and Find Associated Dataset Name ____________\n",
    "print(\"Getting records\")\n",
    "\n",
    "records = client.get_records([int(x[\"record_id\"]) for x in entry_dicts], missing_ok=False)\n",
    "records_to_copy = defaultdict(lambda: defaultdict(list))\n",
    "for rec in records:\n",
    "    try:\n",
    "        response = client.query_dataset_records(record_id=[rec.id])\n",
    "        records_to_copy[response[0][\"dataset_id\"]][response[0][\"specification_name\"]].append(response[0][\"entry_name\"])\n",
    "    except Exception:\n",
    "        print(f\"Failed record {rec.id}, {response}\")\n",
    "    \n",
    "for i, (ds_id, tmp_dict) in enumerate(records_to_copy.items()):\n",
    "    print(f\"Copying entries from ds-{ds_id} ({i+1} of {len(records_to_copy)})\")\n",
    "    for spec_name, entry_names in tmp_dict.items():\n",
    "        dataset.copy_records_from( ds_id, entry_names=entry_names, specification_names=[spec_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec9191a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_record_ids = [rec.id for _, _, rec in dataset.iterate_records()]\n",
    "set(new_record_ids) == set([rec.id for rec in records])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebb91182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# Output for README Part 2\n",
      "\n",
      "* Description: A quantum chemical (QC) dataset curated to train the OpenFF 2.0.0 Sage, with reparametrized Lennard-Jones (LJ) and valence parameters, the latter relevant to this dataset. This QC dataset with the OpenFF default level of theory, B3LYP-D3BJ/DZVP, is used to train Sage parameters. These optimized conformer geometries were used in conjunction with the QC dataset used to train one dimensional torsional profiles. This Generation 2 dataset increases chemical diversity when compared to Generation 1, which are of value to our industry partners. Large molecules (>20 heavy atoms) were also included, offering more flexible molecules and a greater degree of conformational variation which provide intramolecular interactions. This is the complete Optimization dataset used for training OpenFF 2.0.0 Sage, consisting of molecules from the following datasets: OpenFF Gen 2 Opt Set 1 Roche', 'OpenFF Gen 2 Opt Set 2 Coverage', 'OpenFF Gen 2 Opt Set 3 Pfizer Discrepancy', 'OpenFF Gen 2 Opt Set 4 eMolecules  - Discrepancy', and 'OpenFF Gen 2 Opt Set 5 Bayer'. The filters were applied: following filters were applied: RecordStatusFilter(status=RecordStatusEnum.complete), ConnectivityFilter(tolerance=1.2), UndefinedStereoFilter(), ConformerRMSDFilter(max_conformers=10), and ElementFilter(allowed_elements=['H', 'C', 'N', 'O', 'S', 'P', 'F', 'Cl', 'Br', 'I']). Further information can be found in the curation scripts for the linked repositories.\n",
      "* Purpose: B3LYP-D3BJ/DZVP conformers applicable to drug-like molecules for OpenFF 2.0.0 Sage\n",
      "* Name: OpenFF Sage 2.0.0 Optimization Training Dataset v1.1\n",
      "* Submitter: jaclark5\n",
      "\n",
      "\n",
      "## Metadata\n",
      "* Elements: {Br, C, N, H, I, P, F, Cl, O, S}\n",
      "* Program: geometric\n",
      "* QC Specifications: default\n",
      "  * program: psi4\n",
      "  * driver: SinglepointDriver.deferred\n",
      "  * method: b3lyp-d3bj\n",
      "  * basis: dzvp\n",
      "  * keywords: {'maxiter': 200, 'scf_properties': ['dipole', 'quadrupole', 'wiberg_lowdin_indices', 'mayer_indices']}\n",
      "  * protocols: {}\n",
      "  * SCF Properties:\n",
      "    * dipole\n",
      "    * quadrupole\n",
      "    * wiberg_lowdin_indices\n",
      "    * mayer_indices\n"
     ]
    }
   ],
   "source": [
    "# _________ Write Output Part 2 (Run After Approval) ____________\n",
    "\n",
    "elements = set(\n",
    "    sym\n",
    "    for entry in dataset.iterate_entries()\n",
    "    for sym in entry.initial_molecule.symbols\n",
    ")\n",
    "\n",
    "print(\"\\n\\n# Output for README Part 2\\n\")\n",
    "print(\"* Description: {}\".format(dataset.description))\n",
    "print(\"* Purpose: {}\".format(dataset.tagline))\n",
    "print(\"* Name: {}\".format(dataset.name))\n",
    "print(\"* Submitter: {}\\n\".format(dataset.extras[\"submitter\"]))\n",
    "\n",
    "print(\"\\n## Metadata\")\n",
    "print(f\"* Elements: {{{', '.join(elements)}}}\")\n",
    "\n",
    "for spec, obj in dataset.specifications.items():\n",
    "    od = obj.dict()['specification']\n",
    "    print(\"* Program:\", od[\"program\"])\n",
    "    od = od[\"qc_specification\"]\n",
    "    print(\"* QC Specifications:\", spec)\n",
    "    for field, value in od.items():\n",
    "        print(f\"  * {field}: {od[field]}\")\n",
    "    print(\"  * SCF Properties:\")\n",
    "    for field in od[\"keywords\"][\"scf_properties\"]:\n",
    "        print(f\"    * {field}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95201f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaffold.to_json(dataset, compress=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
