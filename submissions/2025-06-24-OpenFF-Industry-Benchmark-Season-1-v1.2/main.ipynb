{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58a7c165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import datetime\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from qcportal.external import scaffold\n",
    "from qcportal import PortalClient\n",
    "\n",
    "from qcfractal.snowflake import FractalSnowflake\n",
    "snowflake = FractalSnowflake()\n",
    "client = snowflake.client()\n",
    "\n",
    "#ADDRESS = \"https://api.qcarchive.molssi.org:443/\"\n",
    "#client = PortalClient(ADDRESS, cache_dir=\".\",)\n",
    "#client = PortalClient(\n",
    "#    ADDRESS, \n",
    "#    username=os.environ['QCARCHIVE_USER'],\n",
    "#    password=os.environ['QCARCHIVE_PASSWORD'],\n",
    "#    cache_dir=\".\",\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865126a7",
   "metadata": {},
   "source": [
    "# Get Records and Molecular Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d506e035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting record ids to remove\n"
     ]
    }
   ],
   "source": [
    "# _________ Pull Record IDs of Relevant Datasets ____________\n",
    "print(\"Getting record ids to remove\")\n",
    "\n",
    "file = requests.get(\n",
    "    \"https://raw.githubusercontent.com/openforcefield/sage-2.2.0/refs/heads/main/05_benchmark_forcefield/process_bm/problem_ids/all_r7_outliers.txt\"\n",
    ")\n",
    "remove_record_ids = set([int(x) for x in file.content.decode().splitlines()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "560b6629",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = \"optimization\"\n",
    "dataset_to_copy = client.get_dataset(dataset_type, \"OpenFF Industry Benchmark Season 1 v1.1\")\n",
    "specs_to_copy = dataset_to_copy.specification_names\n",
    "provenance = dataset_to_copy.provenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa333c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_to_copy.fetch_records(include=[\"initial_molecule\"]) # 30 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286a4fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 539385\n",
      "10001 of 539385\n",
      "20001 of 539385\n",
      "30001 of 539385\n",
      "40001 of 539385\n",
      "50001 of 539385\n",
      "60001 of 539385\n",
      "70001 of 539385\n",
      "80001 of 539385\n",
      "90001 of 539385\n",
      "100001 of 539385\n",
      "110001 of 539385\n",
      "120001 of 539385\n",
      "130001 of 539385\n",
      "140001 of 539385\n",
      "150001 of 539385\n",
      "160001 of 539385\n",
      "170001 of 539385\n",
      "180001 of 539385\n",
      "190001 of 539385\n",
      "200001 of 539385\n",
      "210001 of 539385\n",
      "220001 of 539385\n",
      "230001 of 539385\n",
      "240001 of 539385\n",
      "250001 of 539385\n",
      "260001 of 539385\n",
      "270001 of 539385\n",
      "280001 of 539385\n",
      "290001 of 539385\n",
      "300001 of 539385\n",
      "310001 of 539385\n",
      "320001 of 539385\n",
      "330001 of 539385\n",
      "340001 of 539385\n",
      "350001 of 539385\n",
      "360001 of 539385\n",
      "370001 of 539385\n",
      "380001 of 539385\n",
      "390001 of 539385\n",
      "400001 of 539385\n",
      "410001 of 539385\n",
      "420001 of 539385\n",
      "430001 of 539385\n",
      "440001 of 539385\n",
      "450001 of 539385\n",
      "460001 of 539385\n",
      "470001 of 539385\n",
      "480001 of 539385\n",
      "490001 of 539385\n",
      "500001 of 539385\n",
      "510001 of 539385\n",
      "520001 of 539385\n",
      "530001 of 539385\n"
     ]
    }
   ],
   "source": [
    "nrecords = dataset_to_copy.record_count\n",
    "\n",
    "old_record_ids = []\n",
    "entries_to_copy = []\n",
    "conformer_counts = defaultdict(lambda: 0)\n",
    "\n",
    "# Accessing initial molecule information from record information is slow, so get entry names first\n",
    "for i, (entry_name, spec, rec) in enumerate(dataset_to_copy.iterate_records()):\n",
    "    if i % 100000 == 0:\n",
    "        print(f\"{i+1} of {nrecords}\")\n",
    "    if rec.id not in remove_record_ids:\n",
    "        entries_to_copy.append(entry_name)\n",
    "        old_record_ids.append(rec.id)\n",
    "        conformer_counts[entry_name.split(\"-\")[1]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93d1ee07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating over entries is much faster\n",
    "molecular_properties = {\n",
    "    \"charges\": set(), \n",
    "    \"elements\": set(), \n",
    "    \"masses\": np.zeros(nrecords-len(remove_record_ids))\n",
    "}\n",
    "for i, entry in enumerate(dataset_to_copy.iterate_entries(entry_names=entries_to_copy)):\n",
    "    molecular_properties[\"charges\"].add(entry.initial_molecule.molecular_charge)\n",
    "    for sym in set(entry.initial_molecule.symbols):\n",
    "        molecular_properties[\"elements\"].add(sym)\n",
    "    molecular_properties[\"masses\"][i] = sum(entry.initial_molecule.masses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1471650",
   "metadata": {},
   "source": [
    "# Make New Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "529e82b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing new dataset\n"
     ]
    }
   ],
   "source": [
    "# _________ Initialize New Dataset ____________\n",
    "print(\"Initializing new dataset\")\n",
    "with open(\"ds_info.json\") as f:\n",
    "    dataset_information = json.load(f)\n",
    "\n",
    "dataset = client.add_dataset(\n",
    "    dataset_type,\n",
    "    dataset_information[\"dataset_name\"],\n",
    "    tagline=dataset_information[\"dataset_tagline\"],\n",
    "    description=dataset_information[\"description\"],\n",
    "    provenance=provenance,\n",
    "    default_tag=\"openff\",\n",
    "    owner_user=\"openffbot\",\n",
    "    extras={\n",
    "        \"submitter\": dataset_information[\"metadata.submitter\"],\n",
    "        \"creation_date\": str(datetime.date.today()),\n",
    "        'collection_type': 'OptimizationDataset',\n",
    "        'long_description_url': dataset_information[\"metadata.long_description_url\"],\n",
    "        \"short description\": dataset_information[\"dataset_tagline\"],\n",
    "        \"dataset_name\": dataset_information[\"dataset_name\"],\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e29790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _________ Copy Records ____________\n",
    "print(\"Copy records\")\n",
    "dataset.copy_records_from( dataset_to_copy.id, entry_names=entries_to_copy, specification_names=specs_to_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9191a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_record_ids = [rec.id for _, _, rec in dataset.iterate_records()]\n",
    "set(new_record_ids) == set(old_record_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1573b4df",
   "metadata": {},
   "source": [
    "## Write Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95c66e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Molecular Statistics\n",
      "* Number of unique molecules: 2973\n",
      "* Number of conformers: 539356\n",
      "* Number of conformers (min, mean, max): 7, 181, 469\n",
      "* Molecular weight (min, mean, max): 16.03, 362.35, 1104.40\n",
      "* Charges: -2.0, -1.0, 0.0, 1.0, 2.0\n",
      "* Elements: Br, C, Cl, F, H, N, O, P, S\n"
     ]
    }
   ],
   "source": [
    "# _________ Write Output Part 1 (Run Before Approval) ____________\n",
    "print(\"Generating Molecular Statistics\")\n",
    "\n",
    "molecular_properties[\"charges\"] = sorted(molecular_properties[\"charges\"])\n",
    "molecular_properties[\"elements\"] = sorted(molecular_properties[\"elements\"])\n",
    "\n",
    "print(f\"* Number of unique molecules: {len(conformer_counts)}\")\n",
    "print(\"* Number of conformers:\", int(sum(conformer_counts.values())))\n",
    "print(\n",
    "    \"* Number of conformers (min, mean, max): {}, {}, {}\".format(\n",
    "        int(min(conformer_counts.values())), \n",
    "        int(np.mean(list(conformer_counts.values()))), \n",
    "        int(max(conformer_counts.values()))\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"* Molecular weight (min, mean, max): {:.2f}, {:.2f}, {:.2f}\".format(\n",
    "        min(molecular_properties[\"masses\"]), np.mean(molecular_properties[\"masses\"]), max(molecular_properties[\"masses\"])\n",
    "    )\n",
    ")\n",
    "print(\"* Charges: {}\".format(\", \".join([str(x) for x in molecular_properties[\"charges\"]])))\n",
    "print(\"* Elements: {}\".format(\", \".join([str(x) for x in molecular_properties[\"elements\"]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb91182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _________ Write Output Part 2 (Run After Approval) ____________\n",
    "\n",
    "print(\"* Elements: {}\".format(\", \".join([str(x) for x in molecular_properties[\"elements\"]])))\n",
    "print(\"\\n\\n# Output for README Part 2\\n\")\n",
    "print(\"* Description: {}\".format(dataset.description))\n",
    "print(\"* Purpose: {}\".format(dataset.tagline))\n",
    "print(\"* Name: {}\".format(dataset.name))\n",
    "print(\"* Submitter: {}\\n\".format(dataset.extras[\"submitter\"]))\n",
    "\n",
    "print(\"\\n## Metadata\")\n",
    "print(f\"* Elements: {{{', '.join(molecular_properties[\"elements\"])}}}\")\n",
    "\n",
    "for spec, obj in dataset.specifications.items():\n",
    "    od = obj.dict()['specification']\n",
    "    print(\"* Program:\", od[\"program\"])\n",
    "    od = od[\"qc_specification\"]\n",
    "    print(\"* QC Specifications:\", spec)\n",
    "    for field, value in od.items():\n",
    "        print(f\"  * {field}: {od[field]}\")\n",
    "    print(\"  * SCF Properties:\")\n",
    "    for field in od[\"keywords\"][\"scf_properties\"]:\n",
    "        print(f\"    * {field}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95201f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaffold.to_json(dataset, compress=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
