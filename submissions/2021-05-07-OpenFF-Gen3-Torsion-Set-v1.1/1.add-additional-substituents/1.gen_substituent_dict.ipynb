{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd03f686313755bcadff004b32b3a264512900f6fe94412da81777c3d7c2d59aca7",
   "display_name": "Python 3.8.8 64-bit ('constructure2': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_smirks, is_center_bond_single, smiles_to_image_grid_mod, get_matching_substituents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# uncovered: 46, # poorly covered: 4\n# single uncovered: 20\n 0: t8, [#35:1]-[#6X4:2]-[#6X4:3]-[#35:4]\n 1: t12, [#1:1]-[#6X4:2]-[#6X4:3]-[#35:4]\n 2: t30, [#6X3:1]-[#6X4;r3:2]-[#6X3:3]-[#7X3:4]\n 3: t31, [#6X3:1]-[#6X4;r3:2]-[#6X3:3]=[#8X1:4]\n 4: t32, [#6X3:1]-[#6X4;r3:2]-[#6X3:3]~[#6X3:4]\n 5: t33, [#7X3:1]-[#6X4;r3:2]-[#6X3:3]~[#6X3:4]\n 6: t36, [#6X4;r3:1]-;@[#6X4;r3:2]-[#6X3;r5:3]-;@[#6X3;r5:4]\n 7: t50, [*:1]-[#6X4:2]-[#7X4:3]-[*:4]\n 8: t51b, [*:1]-[#6X4:2]-[#7X3:3]-[#7X2:4]=[#7X2,#8X1]\n 9: t51bh, [#1:1]-[#6X4:2]-[#7X3:3]-[#7X2:4]=[#7X2,#8X1]\n 10: t51c, [*:1]-[#6X4:2]-[#7X3$(*@1-[*]=,:[*][*]=,:[*]@1):3]-[*:4]\n 11: t51ch, [#1:1]-[#6X4:2]-[#7X3$(*@1-[*]=,:[*][*]=,:[*]@1):3]-[*:4]\n 12: t58, [*:1]-[#7X4:2]-[#6X3:3]~[*:4]\n 13: t68, [*:1]~[#7X3,#7X2-1:2]-[#6X3:3]~[*:4]\n 14: t104, [*:1]=[#8X2+1:2]-[#6:3]~[*:4]\n 15: t117, [*:1]-[#8:2]-[#8H1:3]-[*:4]\n 16: t136, [#6X3:1]-[#16X4,#16X3+0:2]-[#7X4,#7X3:3]-[#1:4]\n 17: t138, [#6X3:1]-[#16X4,#16X3+0:2]-[#7X4,#7X3:3]-[#6X4:4]\n 18: t141, [#6X3:1]-[#16X4,#16X3+0:2]-[#7X3:3]-[#6X3:4]\n 19: t157, [*:1]~[*:2]-[*:3]#[*:4]\n"
     ]
    }
   ],
   "source": [
    "# 1. find uncovered torsions\n",
    "import pickle\n",
    "round1 = pickle.load(open('tid_clusters_list.p','rb'))\n",
    "from openff.toolkit.typing.engines.smirnoff import ForceField\n",
    "forcefield = ForceField('result.offxml',allow_cosmetic_attributes=True)\n",
    "ff_torsion_param_list = forcefield.get_parameter_handler('ProperTorsions').parameters\n",
    "\n",
    "uncovered = []\n",
    "poorly_covered = []\n",
    "for tid, clusters in round1.items():\n",
    "    if len(clusters) == 0:\n",
    "        uncovered.append(tid)\n",
    "    elif len(clusters) <3 :\n",
    "        poorly_covered.append(tid)\n",
    "\n",
    "print(f'# uncovered: {len(uncovered)}, # poorly covered: {len(poorly_covered)}')\n",
    "\n",
    "single_uncovered = []\n",
    "for tid in uncovered: \n",
    "    smirks = get_smirks(ff_torsion_param_list, tid)\n",
    "    if is_center_bond_single(smirks):\n",
    "        single_uncovered.append(tid)\n",
    "print(f'# single uncovered: {len(single_uncovered)}')\n",
    "\n",
    "for count, uncovered_tid in enumerate(single_uncovered):\n",
    "    smirks = get_smirks(ff_torsion_param_list, uncovered_tid)\n",
    "    print(f' {count}: {uncovered_tid}, {smirks}')\n",
    "\n",
    "pickle.dump(single_uncovered, open('single_uncovered.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load the substituent list \n",
    "substituents_filtered=pickle.load(open('substituents_filtered.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load additional substituent list (hand-picked)\n",
    "with open('supplemental_substituents.smi','r') as file:\n",
    "    supplemental_substituents = [\n",
    "        line for line in file.read().split(\"\\n\") if len(line) > 0\n",
    "    ]\n",
    "smiles_to_image_grid_mod(supplemental_substituents, output_path='supplemental_substituents.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# substituents: 292\n# additional substituents: 17\n# tot: 309\n"
     ]
    }
   ],
   "source": [
    "# 4. combine the lists\n",
    "substituents_filtered_new = set(substituents_filtered)\n",
    "substituents_filtered_new.update(supplemental_substituents)\n",
    "\n",
    "print(f'# substituents: {len(substituents_filtered)}')\n",
    "print(f'# additional substituents: {len(supplemental_substituents)}')\n",
    "print(f'# tot: {len(substituents_filtered_new)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. gen dict[tid]={frag1:[sub1, sub2, ...], frag2: [suba, subb, ...]}\n",
    "selected_substituents_tot = dict()\n",
    "for uncovered_tid in single_uncovered:\n",
    "    smirks = get_smirks(ff_torsion_param_list, uncovered_tid)\n",
    "    selected_substituents = get_matching_substituents(smirks, substituents_filtered_new)\n",
    "    selected_substituents_tot[uncovered_tid] = selected_substituents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tid, frags in selected_substituents_tot.items():\n",
    "    for frag, sublist in frags.items():\n",
    "        if len(sublist) == 0: \n",
    "            print(tid, frag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(selected_substituents_tot, open('selected_substituent_dict.p','wb'))"
   ]
  }
 ]
}