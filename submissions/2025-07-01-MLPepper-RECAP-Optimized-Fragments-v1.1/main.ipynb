{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58a7c165",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json, sys\n",
    "import requests\n",
    "import datetime\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import periodictable\n",
    "\n",
    "from qcportal.external import scaffold\n",
    "from qcportal import PortalClient\n",
    "from qcportal.serialization import encode_to_json\n",
    "from qcportal.optimization import OptimizationDatasetEntry\n",
    "from qcportal.torsiondrive import TorsiondriveDatasetEntry\n",
    "DatasetEntry = {\"optimization\": OptimizationDatasetEntry, \"torsiondrive\": TorsiondriveDatasetEntry}\n",
    "\n",
    "ADDRESS = \"https://api.qcarchive.molssi.org:443/\"\n",
    "client = PortalClient(ADDRESS, cache_dir=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865126a7",
   "metadata": {},
   "source": [
    "# Get Datasets Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d506e035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting datasets\n"
     ]
    }
   ],
   "source": [
    "# _________ Pull Record IDs of Relevant Datasets ____________\n",
    "print(\"Getting datasets\")\n",
    "\n",
    "datasets = [\n",
    "    client.get_dataset(\"singlepoint\", \"MLPepper RECAP Optimized Fragments v1.0\"),\n",
    "    client.get_dataset(\"singlepoint\", \"MLPepper RECAP Optimized Fragments v1.0 Add Iodines\"),\n",
    "]\n",
    "dataset_type = datasets[0].dataset_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33a76ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting records\n"
     ]
    }
   ],
   "source": [
    "# _________ Get Records ____________\n",
    "print(\"Getting records\")\n",
    "records = []\n",
    "entry_spec_by_ds_id = defaultdict(lambda: defaultdict(list))\n",
    "for ds in datasets:\n",
    "    for entry_name, spec_name, rec in ds.iterate_records():\n",
    "        records.append(rec)\n",
    "        entry_spec_by_ds_id[ds.id][spec_name].append(entry_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e2fbdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 150194 records and 56351 unique SMILES strings (unique molecules)\n"
     ]
    }
   ],
   "source": [
    "cmiles_count = defaultdict(Counter)\n",
    "molecules = []\n",
    "for rec in records:\n",
    "    cmiles = rec.molecule.extras['canonical_isomeric_explicit_hydrogen_mapped_smiles']\n",
    "\n",
    "    if cmiles not in cmiles_count:\n",
    "        molecules.append(rec.molecule)\n",
    "    hash = rec.molecule.get_hash()\n",
    "    cmiles_count[cmiles][hash] += 1\n",
    "\n",
    "print(f\"There are {len(records)} records and {len(cmiles_count)} unique SMILES strings (unique molecules)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c32e1770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Molecular Statistics\n"
     ]
    }
   ],
   "source": [
    "# _________ Pull Statistics from Dataset ____________\n",
    "     \n",
    "print(\"Generating Molecular Statistics\")\n",
    "\n",
    "lx = len(cmiles_count)\n",
    "n_confs, n_heavy_atoms, masses, unique_charges = np.zeros(lx), [], np.zeros(lx), np.zeros(lx)\n",
    "elements = []\n",
    "for i, (cmiles, hashes) in enumerate(cmiles_count.items()):\n",
    "    n_confs[i] = len(hashes)\n",
    "    n_heavy_atoms.append(len([x for x in molecules[i].symbols if x != \"H\"]))\n",
    "    elements.extend(list(set([x for x in molecules[i].symbols])))\n",
    "    masses[i] = sum([getattr(periodictable, x).mass for x in molecules[i].symbols])\n",
    "    unique_charges[i] = molecules[i].molecular_charge\n",
    "    \n",
    "unique_charges = sorted(set(unique_charges))\n",
    "\n",
    "elements = sorted(list(set(elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf1a7e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Heavy Atom Counts\n",
      "  1: 1\n",
      "  2: 2\n",
      "  3: 73\n",
      "  4: 197\n",
      "  5: 558\n",
      "  6: 1338\n",
      "  7: 2957\n",
      "  8: 5728\n",
      "  9: 8617\n",
      " 10: 10872\n",
      " 11: 12697\n",
      " 12: 12632\n",
      " 13: 52\n",
      " 14: 102\n",
      " 15: 61\n",
      " 16: 90\n",
      " 17: 128\n",
      " 18: 111\n",
      " 19: 71\n",
      " 20: 46\n",
      " 21: 2\n",
      " 22: 2\n",
      " 23: 9\n",
      " 24: 2\n",
      " 25: 1\n",
      " 29: 2\n",
      "* Number of unique molecules: 56351\n",
      "* Number of conformers: 75097\n",
      "* Number of conformers (min, mean, max): 1.00, 1.33, 5.00\n",
      "* Molecular weight (min, mean, max): 32.12, 163.20, 701.59\n",
      "* Charges: -4.0, -3.0, -2.0, -1.0, 0.0, 1.0, 2.0, 3.0\n"
     ]
    }
   ],
   "source": [
    "# _________ Write Output Part 1 (Run Before Approval) ____________\n",
    "\n",
    "print(\"\\n# Heavy Atom Counts\")\n",
    "counts1 = Counter(n_heavy_atoms)\n",
    "for n_heavy in sorted(counts1):\n",
    "    print(f\"{str(n_heavy):>3}: {counts1[n_heavy]}\")\n",
    "\n",
    "print(\"* Number of unique molecules: {}\".format(len(cmiles_count)))\n",
    "print(\"* Number of conformers:\", int(sum(n_confs)))\n",
    "print(\n",
    "    \"* Number of conformers (min, mean, max): {:.2f}, {:.2f}, {:.2f}\".format(\n",
    "        min(n_confs), np.mean(n_confs), max(n_confs)\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"* Molecular weight (min, mean, max): {:.2f}, {:.2f}, {:.2f}\".format(\n",
    "        min(masses), np.mean(masses), max(masses)\n",
    "    )\n",
    ")\n",
    "print(\"* Charges: {}\".format(\", \".join([str(x) for x in unique_charges])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "854d448e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "Stop Here Until PR Gains Approval",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m Stop Here Until PR Gains Approval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jenniferclark/mamba/envs/qca-clean/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3678: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "sys.exit(\"Stop Here Until PR Gains Approval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1471650",
   "metadata": {},
   "source": [
    "# Make New Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529e82b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _________ Initialize New Dataset ____________\n",
    "print(\"Initializing new dataset\")\n",
    "with open(\"ds_info.json\") as f:\n",
    "    dataset_information = json.load(f)\n",
    "\n",
    "dataset = client.add_dataset(\n",
    "    dataset_type,\n",
    "    dataset_information[\"dataset_name\"],\n",
    "    tagline=dataset_information[\"dataset_tagline\"],\n",
    "    description=dataset_information[\"description\"],\n",
    "    provenance={},\n",
    "    default_tag=\"openff\",\n",
    "    owner_user=\"openffbot\",\n",
    "    extras={\n",
    "        \"submitter\": dataset_information[\"metadata.submitter\"],\n",
    "        \"creation_data\": str(datetime.date.today()),\n",
    "        'collection_type': 'OptimizationDataset',\n",
    "        'long_description_url': dataset_information[\"metadata.long_description_url\"],\n",
    "        \"short description\": dataset_information[\"dataset_tagline\"],\n",
    "        \"dataset_name\": dataset_information[\"dataset_name\"],\n",
    "        \"elements\": elements,\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e29790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ds associated with specifications\n",
    "# _________ Get Records and Find Associated Dataset Name ____________\n",
    "print(\"Getting records\")\n",
    "\n",
    "for ds_id, spec_entries in entry_spec_by_ds_id:\n",
    "    for spec_name, entry_names in spec_entries.items():\n",
    "        dataset.copy_records_from( ds_id, entry_names=entry_names, specification_names=[spec_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9191a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_record_ids = [rec.id for _, _, rec in dataset.iterate_records()]\n",
    "set(new_record_ids) == set([rec.id for rec in records])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb91182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _________ Write Output Part 2 (Run After Approval) ____________\n",
    "\n",
    "elements = set(\n",
    "    sym\n",
    "    for entry in dataset.iterate_entries()\n",
    "    for sym in entry.initial_molecule.symbols\n",
    ")\n",
    "\n",
    "print(\"\\n\\n# Output for README Part 2\\n\")\n",
    "print(\"* Description: {}\".format(dataset.description))\n",
    "print(\"* Purpose: {}\".format(dataset.tagline))\n",
    "print(\"* Name: {}\".format(dataset.name))\n",
    "print(\"* Submitter: {}\\n\".format(dataset.extras[\"submitter\"]))\n",
    "\n",
    "print(\"\\n## Metadata\")\n",
    "print(f\"* Elements: {{{', '.join(elements)}}}\")\n",
    "\n",
    "for spec, obj in dataset.specifications.items():\n",
    "    od = obj.dict()['specification']\n",
    "    print(\"* Program:\", od[\"program\"])\n",
    "    od = od[\"qc_specification\"]\n",
    "    print(\"* QC Specifications:\", spec)\n",
    "    for field, value in od.items():\n",
    "        print(f\"  * {field}: {od[field]}\")\n",
    "    print(\"  * SCF Properties:\")\n",
    "    for field in od[\"keywords\"][\"scf_properties\"]:\n",
    "        print(f\"    * {field}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95201f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaffold.to_json(dataset, compress=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
